{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d05ec2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.feather as feather\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import math\n",
    "import xgboost\n",
    "\n",
    "import sklearn.gaussian_process as gp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b64e90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.2239402825693408"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_IU = feather.read_feather('df_IU.feather')\n",
    "df_PQ = feather.read_feather('df_PQ.feather')\n",
    "\n",
    "\n",
    "df_IU.fillna(0, inplace=True)\n",
    "df_PQ.fillna(0, inplace=True)\n",
    "\n",
    "cols = df_PQ.columns\n",
    "\n",
    "P_sum = sum([df_PQ[name] for name in cols if \"P\" in name])\n",
    "Q_sum = sum([df_PQ[name] for name in cols if \"Q\" in name])\n",
    "\n",
    "df_PQ.insert(2, \"P_sum\", P_sum)\n",
    "df_PQ.insert(3, \"Q_sum\", Q_sum)\n",
    "df_PQ[\"P_sum\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12e3a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts a time amount in 'nanoseconds' to an amount in '5 minutes'\n",
    "def ns_to_5m(x):\n",
    "    return x/(pow(10,9)*60*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05c9fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values on \"DATUM_TIJD\"\n",
    "df_IU = df_IU.sort_values(\"DATUM_TIJD\")\n",
    "df_PQ = df_PQ.sort_values(\"DATUM_TIJD\")\n",
    "\n",
    "# .value returns time in nanoseconds, starting form unix time.\n",
    "# Get starting timestamp and convert this to '5 minutes'\n",
    "start_time = ns_to_5m(df_IU[\"DATUM_TIJD\"].iloc[1].value)\n",
    "\n",
    "# Convert each DATETIME timestamp to a float value representing the amount of 5 minutes since start time\n",
    "df_IU[\"DATUM_TIJD\"] = df_IU['DATUM_TIJD'].apply(lambda x: ns_to_5m(x.value)-start_time)\n",
    "df_PQ[\"DATUM_TIJD\"] = df_PQ['DATUM_TIJD'].apply(lambda x: ns_to_5m(x.value)-start_time)\n",
    "\n",
    "df_IU = df_IU.reset_index(drop=True)\n",
    "df_PQ = df_PQ.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a488c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce timescale\n",
    "def weeks_to_5_mins(weeks):\n",
    "    return 12*24*7*weeks\n",
    "\n",
    "def reduce_timescale(df, weeks):\n",
    "    weeks = weeks_to_5_mins(weeks)\n",
    "    df = df[df[\"DATUM_TIJD\"] <= weeks]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94f52b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_percentage_dead_space(Xs):\n",
    "    dead_space = np.zeros(len(Xs))\n",
    "    total = Xs[0].stack().value_counts().sum()\n",
    "    for index, df in enumerate(Xs):\n",
    "        zeros = df.stack().value_counts()[0]\n",
    "        dead_space[index] = zeros/total\n",
    "    return dead_space\n",
    "\n",
    "\n",
    "\n",
    "# input - df: a Dataframe, chunkSize: the chunk size\n",
    "# output - a list of DataFrame\n",
    "# purpose - splits the DataFrame into smaller chunks\n",
    "def split_dataframe(df, chunk_size): \n",
    "    chunks = list()\n",
    "    num_stations = len(df_IU[\"STATION\"].unique())\n",
    "    num_chunks = len(df) // (chunk_size*num_stations) + 1\n",
    "    print(num_chunks)\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return chunks\n",
    "    \n",
    "\n",
    "def split_on_stations(df_IU, df_PQ):\n",
    "    \n",
    "    df_IU = reduce_timescale(df_IU, 2)\n",
    "    df_PQ = reduce_timescale(df_PQ, 2)\n",
    "    \n",
    "    stations = df_IU[\"STATION\"].unique()\n",
    "\n",
    "    dfs_IU = []\n",
    "    dfs_PQ = []\n",
    "\n",
    "    for station in stations:\n",
    "        temp_IU = df_IU[df_IU[\"STATION\"]==station]\n",
    "        temp_PQ = df_PQ[df_PQ[\"STATION\"]==station]\n",
    "\n",
    "        del temp_PQ[\"DATUM_TIJD\"]\n",
    "        del temp_IU[\"STATION\"], temp_PQ[\"STATION\"]\n",
    "        \n",
    "        temp_PQ.reset_index(drop = True, inplace = True)\n",
    "        temp_IU.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        dfs_IU.append(temp_IU)\n",
    "        dfs_PQ.append(temp_PQ)\n",
    "    \n",
    "    return dfs_IU, dfs_PQ\n",
    "\n",
    "def split_on_weeks(df_IU, df_PQ):   \n",
    "    dfs_IU = split_dataframe(df_IU, weeks_to_5_mins(2))\n",
    "    dfs_PQ = split_dataframe(df_PQ, weeks_to_5_mins(2))\n",
    "    \n",
    "    for index in range(len(dfs_IU)):\n",
    "        temp_IU = dfs_IU[index].reset_index(drop=True)\n",
    "        temp_PQ = dfs_PQ[index].reset_index(drop=True)\n",
    "        \n",
    "        del temp_PQ[\"DATUM_TIJD\"]\n",
    "        del temp_IU[\"STATION\"], temp_PQ[\"STATION\"]\n",
    "        \n",
    "        dfs_IU[index] = temp_IU\n",
    "        dfs_PQ[index] = temp_PQ\n",
    "    \n",
    "    return dfs_IU, dfs_PQ\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def cross_validation(Xs, ys):\n",
    "    matrix = np.zeros((len(ys),len(ys),3))\n",
    "    alpha = 10\n",
    "    for x_index, X_train in enumerate(Xs):\n",
    "        y_train = ys[x_index]\n",
    "        for y_index, y_test in enumerate(ys):\n",
    "            print(\"X: {0}, Y: {1}\".format(x_index, y_index))\n",
    "            X_test = Xs[y_index]\n",
    "            df_predict = XGboost_regression(X_train, y_train, X_test)\n",
    "            \n",
    "            P,_ = predict_sign(df_predict, y_test)\n",
    "            mse = mean_squared_error(y_test, df_predict)\n",
    "            R = r2_score(y_test, df_predict)\n",
    "            \n",
    "            matrix[x_index, y_index, 0] = P\n",
    "            matrix[x_index, y_index, 1] = mse\n",
    "            matrix[x_index, y_index, 2] = R\n",
    "            \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1189d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sign(df_predict, y_test):\n",
    "    df_sign = df_predict.copy()\n",
    "    df_y_sign = y_test.copy()\n",
    "    for col in df_sign.columns:\n",
    "        df_sign[col] = df_sign[col].apply(lambda x: -1 if x<0 else 1)\n",
    "        df_y_sign[col] = df_y_sign[col].apply(lambda x: -1 if x<0 else 1)\n",
    "\n",
    "    df_new_sign = df_sign == df_y_sign\n",
    "    \n",
    "    field_accuracies = []\n",
    "    for col in df_new_sign.columns:\n",
    "        field_accuracies.append(df_new_sign[col].value_counts(normalize=True).values[0])\n",
    "\n",
    "    P_accuracies = field_accuracies[::2]\n",
    "    Q_accuracies = field_accuracies[1::2]\n",
    "    \n",
    "    P_avg = sum(P_accuracies)/len(P_accuracies)\n",
    "    Q_avg = sum(Q_accuracies)/len(Q_accuracies)\n",
    "    \n",
    "    return P_avg, Q_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f2484ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "def XGboost_regression(X_train, y_train, X_test):\n",
    "    model = XGBRegressor(objective='reg:squarederror')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predict = model.predict(X_test)\n",
    "    df_predict = pd.DataFrame(predict, columns = y_train.columns, dtype = float)\n",
    "    return df_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c911450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 0, Y: 0\n",
      "X: 0, Y: 1\n",
      "X: 0, Y: 2\n",
      "X: 0, Y: 3\n",
      "X: 0, Y: 4\n",
      "X: 0, Y: 5\n",
      "X: 0, Y: 6\n",
      "X: 0, Y: 7\n",
      "X: 0, Y: 8\n",
      "X: 0, Y: 9\n",
      "X: 1, Y: 0\n",
      "X: 1, Y: 1\n",
      "X: 1, Y: 2\n",
      "X: 1, Y: 3\n",
      "X: 1, Y: 4\n",
      "X: 1, Y: 5\n",
      "X: 1, Y: 6\n",
      "X: 1, Y: 7\n",
      "X: 1, Y: 8\n",
      "X: 1, Y: 9\n",
      "X: 2, Y: 0\n",
      "X: 2, Y: 1\n",
      "X: 2, Y: 2\n",
      "X: 2, Y: 3\n",
      "X: 2, Y: 4\n",
      "X: 2, Y: 5\n",
      "X: 2, Y: 6\n",
      "X: 2, Y: 7\n",
      "X: 2, Y: 8\n",
      "X: 2, Y: 9\n",
      "X: 3, Y: 0\n",
      "X: 3, Y: 1\n",
      "X: 3, Y: 2\n",
      "X: 3, Y: 3\n",
      "X: 3, Y: 4\n",
      "X: 3, Y: 5\n",
      "X: 3, Y: 6\n",
      "X: 3, Y: 7\n",
      "X: 3, Y: 8\n",
      "X: 3, Y: 9\n",
      "X: 4, Y: 0\n",
      "X: 4, Y: 1\n",
      "X: 4, Y: 2\n",
      "X: 4, Y: 3\n",
      "X: 4, Y: 4\n",
      "X: 4, Y: 5\n",
      "X: 4, Y: 6\n",
      "X: 4, Y: 7\n",
      "X: 4, Y: 8\n",
      "X: 4, Y: 9\n",
      "X: 5, Y: 0\n",
      "X: 5, Y: 1\n",
      "X: 5, Y: 2\n",
      "X: 5, Y: 3\n",
      "X: 5, Y: 4\n",
      "X: 5, Y: 5\n",
      "X: 5, Y: 6\n",
      "X: 5, Y: 7\n",
      "X: 5, Y: 8\n",
      "X: 5, Y: 9\n",
      "X: 6, Y: 0\n",
      "X: 6, Y: 1\n",
      "X: 6, Y: 2\n",
      "X: 6, Y: 3\n",
      "X: 6, Y: 4\n",
      "X: 6, Y: 5\n",
      "X: 6, Y: 6\n",
      "X: 6, Y: 7\n",
      "X: 6, Y: 8\n",
      "X: 6, Y: 9\n",
      "X: 7, Y: 0\n",
      "X: 7, Y: 1\n",
      "X: 7, Y: 2\n",
      "X: 7, Y: 3\n",
      "X: 7, Y: 4\n",
      "X: 7, Y: 5\n",
      "X: 7, Y: 6\n",
      "X: 7, Y: 7\n",
      "X: 7, Y: 8\n",
      "X: 7, Y: 9\n",
      "X: 8, Y: 0\n",
      "X: 8, Y: 1\n",
      "X: 8, Y: 2\n",
      "X: 8, Y: 3\n",
      "X: 8, Y: 4\n",
      "X: 8, Y: 5\n",
      "X: 8, Y: 6\n",
      "X: 8, Y: 7\n",
      "X: 8, Y: 8\n",
      "X: 8, Y: 9\n",
      "X: 9, Y: 0\n",
      "X: 9, Y: 1\n",
      "X: 9, Y: 2\n",
      "X: 9, Y: 3\n",
      "X: 9, Y: 4\n",
      "X: 9, Y: 5\n",
      "X: 9, Y: 6\n",
      "X: 9, Y: 7\n",
      "X: 9, Y: 8\n",
      "X: 9, Y: 9\n"
     ]
    }
   ],
   "source": [
    "Xs, ys = split_on_stations(df_IU, df_PQ)\n",
    "matrix = cross_validation(Xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e0843c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.23675828e-01  1.21908558e+01 -4.09548524e+00]\n",
      " [ 9.72374847e-01  1.11178445e-02  2.30285751e-01]\n",
      " [ 9.25700168e-01  3.30292405e+01 -2.47080405e-01]\n",
      " [ 8.75562805e-01  8.85587466e+00 -2.55651688e+02]\n",
      " [ 6.37791896e-01  1.10005865e+01 -2.37134937e+00]\n",
      " [ 9.22714438e-01  9.22609007e+01 -1.21818330e+00]\n",
      " [ 9.72756410e-01  7.12420083e+01 -7.47074820e-01]\n",
      " [ 7.97399649e-01  2.86991457e+01 -8.08142654e-01]\n",
      " [ 8.80590894e-01  9.77806356e+00 -2.98513055e+03]\n",
      " [ 8.36807874e-01  9.67445520e+00 -1.50823183e+02]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trained_on_0</th>\n",
       "      <th>trained_on_1</th>\n",
       "      <th>trained_on_2</th>\n",
       "      <th>trained_on_3</th>\n",
       "      <th>trained_on_4</th>\n",
       "      <th>trained_on_5</th>\n",
       "      <th>trained_on_6</th>\n",
       "      <th>trained_on_7</th>\n",
       "      <th>trained_on_8</th>\n",
       "      <th>trained_on_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tested_on_0</th>\n",
       "      <td>0.000664</td>\n",
       "      <td>4.600247</td>\n",
       "      <td>40.025723</td>\n",
       "      <td>2.419537</td>\n",
       "      <td>2.613171</td>\n",
       "      <td>90.340002</td>\n",
       "      <td>43.860441</td>\n",
       "      <td>15.756260</td>\n",
       "      <td>4.993013</td>\n",
       "      <td>2.835594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_1</th>\n",
       "      <td>12.190856</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>33.029241</td>\n",
       "      <td>8.855875</td>\n",
       "      <td>11.000587</td>\n",
       "      <td>92.260901</td>\n",
       "      <td>71.242008</td>\n",
       "      <td>28.699146</td>\n",
       "      <td>9.778064</td>\n",
       "      <td>9.674455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_2</th>\n",
       "      <td>28.140780</td>\n",
       "      <td>19.450609</td>\n",
       "      <td>0.049828</td>\n",
       "      <td>23.766914</td>\n",
       "      <td>21.361541</td>\n",
       "      <td>156.144990</td>\n",
       "      <td>127.340786</td>\n",
       "      <td>18.565284</td>\n",
       "      <td>30.377413</td>\n",
       "      <td>27.972730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_3</th>\n",
       "      <td>4.229063</td>\n",
       "      <td>5.221819</td>\n",
       "      <td>45.722433</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>4.520874</td>\n",
       "      <td>71.890459</td>\n",
       "      <td>37.934955</td>\n",
       "      <td>25.465763</td>\n",
       "      <td>1.001021</td>\n",
       "      <td>0.967510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_4</th>\n",
       "      <td>1.272928</td>\n",
       "      <td>4.904698</td>\n",
       "      <td>39.696475</td>\n",
       "      <td>2.042520</td>\n",
       "      <td>0.020187</td>\n",
       "      <td>101.566912</td>\n",
       "      <td>43.620376</td>\n",
       "      <td>12.440288</td>\n",
       "      <td>1.829991</td>\n",
       "      <td>2.702045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_5</th>\n",
       "      <td>64.740690</td>\n",
       "      <td>37.845778</td>\n",
       "      <td>124.860640</td>\n",
       "      <td>38.741983</td>\n",
       "      <td>60.551983</td>\n",
       "      <td>0.104233</td>\n",
       "      <td>18.829028</td>\n",
       "      <td>192.764756</td>\n",
       "      <td>38.988891</td>\n",
       "      <td>39.736448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_6</th>\n",
       "      <td>42.894909</td>\n",
       "      <td>23.207294</td>\n",
       "      <td>171.634579</td>\n",
       "      <td>17.115473</td>\n",
       "      <td>30.509354</td>\n",
       "      <td>42.660362</td>\n",
       "      <td>0.049956</td>\n",
       "      <td>80.932785</td>\n",
       "      <td>20.117833</td>\n",
       "      <td>23.552325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_7</th>\n",
       "      <td>10.220485</td>\n",
       "      <td>5.547874</td>\n",
       "      <td>29.292127</td>\n",
       "      <td>18.917329</td>\n",
       "      <td>11.536856</td>\n",
       "      <td>137.398761</td>\n",
       "      <td>66.655237</td>\n",
       "      <td>0.007112</td>\n",
       "      <td>9.550858</td>\n",
       "      <td>7.775018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_8</th>\n",
       "      <td>3.598662</td>\n",
       "      <td>5.545384</td>\n",
       "      <td>46.934311</td>\n",
       "      <td>1.135875</td>\n",
       "      <td>4.102117</td>\n",
       "      <td>70.552044</td>\n",
       "      <td>36.961356</td>\n",
       "      <td>23.971730</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1.208388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_9</th>\n",
       "      <td>3.829675</td>\n",
       "      <td>5.680774</td>\n",
       "      <td>47.836865</td>\n",
       "      <td>3.032046</td>\n",
       "      <td>4.669203</td>\n",
       "      <td>68.565531</td>\n",
       "      <td>36.035941</td>\n",
       "      <td>28.034935</td>\n",
       "      <td>0.302809</td>\n",
       "      <td>0.006614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             trained_on_0  trained_on_1  trained_on_2  trained_on_3  \\\n",
       "tested_on_0      0.000664      4.600247     40.025723      2.419537   \n",
       "tested_on_1     12.190856      0.011118     33.029241      8.855875   \n",
       "tested_on_2     28.140780     19.450609      0.049828     23.766914   \n",
       "tested_on_3      4.229063      5.221819     45.722433      0.000320   \n",
       "tested_on_4      1.272928      4.904698     39.696475      2.042520   \n",
       "tested_on_5     64.740690     37.845778    124.860640     38.741983   \n",
       "tested_on_6     42.894909     23.207294    171.634579     17.115473   \n",
       "tested_on_7     10.220485      5.547874     29.292127     18.917329   \n",
       "tested_on_8      3.598662      5.545384     46.934311      1.135875   \n",
       "tested_on_9      3.829675      5.680774     47.836865      3.032046   \n",
       "\n",
       "             trained_on_4  trained_on_5  trained_on_6  trained_on_7  \\\n",
       "tested_on_0      2.613171     90.340002     43.860441     15.756260   \n",
       "tested_on_1     11.000587     92.260901     71.242008     28.699146   \n",
       "tested_on_2     21.361541    156.144990    127.340786     18.565284   \n",
       "tested_on_3      4.520874     71.890459     37.934955     25.465763   \n",
       "tested_on_4      0.020187    101.566912     43.620376     12.440288   \n",
       "tested_on_5     60.551983      0.104233     18.829028    192.764756   \n",
       "tested_on_6     30.509354     42.660362      0.049956     80.932785   \n",
       "tested_on_7     11.536856    137.398761     66.655237      0.007112   \n",
       "tested_on_8      4.102117     70.552044     36.961356     23.971730   \n",
       "tested_on_9      4.669203     68.565531     36.035941     28.034935   \n",
       "\n",
       "             trained_on_8  trained_on_9  \n",
       "tested_on_0      4.993013      2.835594  \n",
       "tested_on_1      9.778064      9.674455  \n",
       "tested_on_2     30.377413     27.972730  \n",
       "tested_on_3      1.001021      0.967510  \n",
       "tested_on_4      1.829991      2.702045  \n",
       "tested_on_5     38.988891     39.736448  \n",
       "tested_on_6     20.117833     23.552325  \n",
       "tested_on_7      9.550858      7.775018  \n",
       "tested_on_8      0.000021      1.208388  \n",
       "tested_on_9      0.302809      0.006614  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = 1\n",
    "print(matrix[metric])\n",
    "lst = np.arange(matrix.shape[0])\n",
    "cols = [\"trained_on_\" + str(number) for number in lst]\n",
    "rows = [\"tested_on_\" + str(number) for number in lst]\n",
    "\n",
    "pd_crossval_stations = pd.DataFrame(matrix[:,:,metric], index = rows, columns = cols,dtype = float)\n",
    "pd_crossval_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa25f94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = Xs[0]\n",
    "\n",
    "dead_space = calc_percentage_dead_space(Xs)\n",
    "\n",
    "pd_crossval_stations[\"dead_space\"] = dead_space\n",
    "pd_crossval_weeks = pd_crossval_stations.reset_index()\n",
    "pd_crossval_weeks.to_feather(\"station_crossval_XGboost_mse.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "66c73a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Xs[0]\n",
    "y_train = ys[0]\n",
    "X_test = Xs[2]\n",
    "X_test = X_test[X_test[\"DATUM_TIJD\"]==0]\n",
    "\n",
    "model = XGBRegressor(objective='reg:squarederror')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "df_predict = pd.DataFrame(predict, columns = y_train.columns, dtype = float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d03b7e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_sum</th>\n",
       "      <th>Q_sum</th>\n",
       "      <th>P_0</th>\n",
       "      <th>Q_0</th>\n",
       "      <th>P_1</th>\n",
       "      <th>Q_1</th>\n",
       "      <th>P_2</th>\n",
       "      <th>Q_2</th>\n",
       "      <th>P_3</th>\n",
       "      <th>Q_3</th>\n",
       "      <th>...</th>\n",
       "      <th>P_20</th>\n",
       "      <th>Q_20</th>\n",
       "      <th>P_21</th>\n",
       "      <th>Q_21</th>\n",
       "      <th>P_22</th>\n",
       "      <th>Q_22</th>\n",
       "      <th>P_23</th>\n",
       "      <th>Q_23</th>\n",
       "      <th>P_24</th>\n",
       "      <th>Q_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.77114</td>\n",
       "      <td>1.963039</td>\n",
       "      <td>0.063502</td>\n",
       "      <td>0.073118</td>\n",
       "      <td>0.414443</td>\n",
       "      <td>-0.186406</td>\n",
       "      <td>0.08755</td>\n",
       "      <td>0.072204</td>\n",
       "      <td>-4.523394</td>\n",
       "      <td>1.378081</td>\n",
       "      <td>...</td>\n",
       "      <td>1.634508e-16</td>\n",
       "      <td>1.634508e-16</td>\n",
       "      <td>1.634508e-16</td>\n",
       "      <td>1.634508e-16</td>\n",
       "      <td>1.634508e-16</td>\n",
       "      <td>1.634508e-16</td>\n",
       "      <td>1.634508e-16</td>\n",
       "      <td>1.634508e-16</td>\n",
       "      <td>1.634508e-16</td>\n",
       "      <td>1.634508e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     P_sum     Q_sum       P_0       Q_0       P_1       Q_1      P_2  \\\n",
       "0 -4.77114  1.963039  0.063502  0.073118  0.414443 -0.186406  0.08755   \n",
       "\n",
       "        Q_2       P_3       Q_3  ...          P_20          Q_20  \\\n",
       "0  0.072204 -4.523394  1.378081  ...  1.634508e-16  1.634508e-16   \n",
       "\n",
       "           P_21          Q_21          P_22          Q_22          P_23  \\\n",
       "0  1.634508e-16  1.634508e-16  1.634508e-16  1.634508e-16  1.634508e-16   \n",
       "\n",
       "           Q_23          P_24          Q_24  \n",
       "0  1.634508e-16  1.634508e-16  1.634508e-16  \n",
       "\n",
       "[1 rows x 52 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
