{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4de25168",
   "metadata": {},
   "source": [
    "This notebook contains the experimental pipeline for temporal data of MS stations. The main goal is to train regression models based on the features of current and voltage. The prediction goal is the active and reactive power. The first half of the notebook contains pre-processing. Ranging from importing the code, removing excess features, converting date times to an interger time stamp, imputing NaNs, and adding lagged measurements for the current. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77df2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.feather as feather\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "import sklearn.gaussian_process as gp\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb5e07f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column removed -> ROUTE_ID\n",
      "column removed -> ROUTE_NAAM\n",
      "column removed -> TA_B2_NAME\n",
      "column removed -> M_POINT_P\n",
      "column removed -> M_POINT_Q\n",
      "column removed -> M_POINT_I\n",
      "column removed -> M_TIMESTAMP\n",
      "column removed -> FLAG_P\n",
      "column removed -> FLAG_Q\n",
      "column removed -> FLAG_I\n",
      "column removed -> FLAG_MEETFOUT\n",
      "column removed -> FLAG_SCHAKEL_EVENT\n",
      "column removed -> SCHEMA_MS_VELD_ID\n",
      "column removed -> UPDATE_DATUMTIJD\n"
     ]
    }
   ],
   "source": [
    "df = feather.read_feather('ems_metingen_pqi.feather')\n",
    "df['DATUM_TIJD'] = pd.to_datetime(df['DATUM_TIJD'])\n",
    "\n",
    "# preprocessing\n",
    "# uncomment this part of the code if you want to add the in_uitgaand features to the ems dataset\n",
    "\n",
    "# df_excel = pd.read_excel(\"ems_metingen_in_uitgaand.xlsx\")\n",
    "# remove_lst = [3,4,5]\n",
    "# df_excel = df_excel.drop(df_excel.columns[remove_lst], axis = 1)\n",
    "# df_excel = df_excel.replace(\"Uit\", 1)\n",
    "# df_excel = df_excel.replace(\"In\", -1)\n",
    "# df_excel = df_excel.replace(\"nvt\", 0)\n",
    "# df_excel = df_excel.replace(\"defect\", np.NAN)\n",
    "# df = pd.merge(df, df_excel, on=['TA_B1_NAME', 'TA_B2_NAME', 'TA_B3_NAME'], how='left')\n",
    "\n",
    "\n",
    "# Dropping columns\n",
    "remove_list = [0,1,3,5,6,7,8,10,11,12,13,14,15,16]\n",
    "for index in remove_list:\n",
    "    print('column removed ->', df.columns[index])\n",
    "df = df.drop(df.columns[remove_list], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13516ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HrvH' 'Nk' 'Grd' 'Dtn' 'HFDP' 'Dvd-RS' 'Ns' 'Tex' 'Lw' 'Hby']\n",
      "463.96000000000004\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA_B1_NAME</th>\n",
       "      <th>TA_B3_NAME</th>\n",
       "      <th>DATUM_TIJD</th>\n",
       "      <th>M_VALUE_P</th>\n",
       "      <th>M_VALUE_Q</th>\n",
       "      <th>M_VALUE_I</th>\n",
       "      <th>BEDRIJFSSPANNING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3990289</th>\n",
       "      <td>HrvH</td>\n",
       "      <td>V103</td>\n",
       "      <td>2021-05-09 16:50:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962775</th>\n",
       "      <td>HrvH</td>\n",
       "      <td>V104</td>\n",
       "      <td>2021-05-09 16:50:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5769635</th>\n",
       "      <td>HrvH</td>\n",
       "      <td>V105</td>\n",
       "      <td>2021-05-09 16:50:00</td>\n",
       "      <td>-2.83</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>78.51</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914731</th>\n",
       "      <td>HrvH</td>\n",
       "      <td>V108</td>\n",
       "      <td>2021-05-09 16:50:00</td>\n",
       "      <td>-2.83</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>80.10</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6562145</th>\n",
       "      <td>HrvH</td>\n",
       "      <td>V101</td>\n",
       "      <td>2021-05-09 16:50:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6693795</th>\n",
       "      <td>HrvH</td>\n",
       "      <td>V107</td>\n",
       "      <td>2021-05-09 16:50:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7025049</th>\n",
       "      <td>HrvH</td>\n",
       "      <td>V111</td>\n",
       "      <td>2021-05-09 16:50:00</td>\n",
       "      <td>-2.82</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>78.08</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7687412</th>\n",
       "      <td>HrvH</td>\n",
       "      <td>V110</td>\n",
       "      <td>2021-05-09 16:50:00</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.40</td>\n",
       "      <td>71.53</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8279185</th>\n",
       "      <td>HrvH</td>\n",
       "      <td>V109</td>\n",
       "      <td>2021-05-09 16:50:00</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.26</td>\n",
       "      <td>42.79</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8320851</th>\n",
       "      <td>HrvH</td>\n",
       "      <td>V112</td>\n",
       "      <td>2021-05-09 16:50:00</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.27</td>\n",
       "      <td>43.74</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9515552</th>\n",
       "      <td>HrvH</td>\n",
       "      <td>V113</td>\n",
       "      <td>2021-05-09 16:50:00</td>\n",
       "      <td>2.49</td>\n",
       "      <td>0.39</td>\n",
       "      <td>69.21</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10935483</th>\n",
       "      <td>HrvH</td>\n",
       "      <td>V102</td>\n",
       "      <td>2021-05-09 16:50:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11427486</th>\n",
       "      <td>HrvH</td>\n",
       "      <td>V106</td>\n",
       "      <td>2021-05-09 16:50:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TA_B1_NAME TA_B3_NAME          DATUM_TIJD  M_VALUE_P  M_VALUE_Q  \\\n",
       "3990289        HrvH       V103 2021-05-09 16:50:00       0.00       0.00   \n",
       "4962775        HrvH       V104 2021-05-09 16:50:00       0.00       0.00   \n",
       "5769635        HrvH       V105 2021-05-09 16:50:00      -2.83      -0.40   \n",
       "5914731        HrvH       V108 2021-05-09 16:50:00      -2.83      -0.40   \n",
       "6562145        HrvH       V101 2021-05-09 16:50:00       0.00       0.00   \n",
       "6693795        HrvH       V107 2021-05-09 16:50:00       0.00       0.00   \n",
       "7025049        HrvH       V111 2021-05-09 16:50:00      -2.82      -0.40   \n",
       "7687412        HrvH       V110 2021-05-09 16:50:00       2.52       0.40   \n",
       "8279185        HrvH       V109 2021-05-09 16:50:00       1.55       0.26   \n",
       "8320851        HrvH       V112 2021-05-09 16:50:00       1.55       0.27   \n",
       "9515552        HrvH       V113 2021-05-09 16:50:00       2.49       0.39   \n",
       "10935483       HrvH       V102 2021-05-09 16:50:00       0.00       0.00   \n",
       "11427486       HrvH       V106 2021-05-09 16:50:00       0.00       0.00   \n",
       "\n",
       "          M_VALUE_I  BEDRIJFSSPANNING  \n",
       "3990289        0.00             0.021  \n",
       "4962775        0.00             0.021  \n",
       "5769635       78.51             0.021  \n",
       "5914731       80.10             0.021  \n",
       "6562145        0.00             0.021  \n",
       "6693795        0.00             0.021  \n",
       "7025049       78.08             0.021  \n",
       "7687412       71.53             0.021  \n",
       "8279185       42.79             0.021  \n",
       "8320851       43.74             0.021  \n",
       "9515552       69.21             0.021  \n",
       "10935483       0.00             0.021  \n",
       "11427486       0.00             0.021  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = df[df[\"TA_B1_NAME\"]==\"HrvH\"]\n",
    "temp_df = temp_df[temp_df[\"DATUM_TIJD\"]==\"2021-05-9 16:50:00\"]\n",
    "lst = temp_df[\"M_VALUE_I\"].to_list()\n",
    "print(df[\"TA_B1_NAME\"].unique())\n",
    "lst = [abs(x) for x in lst]\n",
    "print(sum(lst))\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2feab82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Calculates current from P, Q, and U'''\n",
    "def calculate_I(P,Q,U):\n",
    "    return np.sqrt(pow(P,2) + pow(Q,2)/(U*np.sqrt(3)))\n",
    "\n",
    "''' boolean to check if only I is NaN '''\n",
    "def only_I_is_nan(P, Q, I):\n",
    "    value = (not np.isnan(P) and not np.isnan(Q)) and np.isnan(I)\n",
    "    return value\n",
    "\n",
    "''' \n",
    "    fills the NaN values in the dataframe.\n",
    "    First compute I where able (If P, Q, and U are known),\n",
    "    then impute the rest of the NaNs with given means for P, Q, and I\n",
    "'''\n",
    "def fill_nan(temp_df, mean_P, mean_Q, mean_I):\n",
    "    # Calculate I from P and Q only if I is NaN and P and Q are not NaNs\n",
    "    temp_df[\"M_VALUE_I\"] = temp_df.apply(lambda x: calculate_I(x[\"M_VALUE_P\"], x[\"M_VALUE_Q\"], x[\"BEDRIJFSSPANNING\"]) if only_I_is_nan(x[\"M_VALUE_P\"], x[\"M_VALUE_Q\"], x[\"M_VALUE_I\"]) else x[\"M_VALUE_I\"], axis=1)\n",
    "\n",
    "    temp_df[\"M_VALUE_P\"] = temp_df[\"M_VALUE_P\"].fillna(value= mean_P)\n",
    "    temp_df[\"M_VALUE_Q\"] = temp_df[\"M_VALUE_Q\"].fillna(value= mean_Q)\n",
    "    temp_df[\"M_VALUE_I\"] = temp_df[\"M_VALUE_I\"].fillna(value= mean_I)\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57e9cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' converts a time amount in 'nanoseconds' to an amount in '5 minutes ''' \n",
    "def ns_to_5m(x):\n",
    "    return x/(pow(10,9)*60*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2879708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"TA_B1_NAME\": \"STATION\"})\n",
    "df = df.rename(columns={\"TA_B3_NAME\": \"FIELD\"})\n",
    "\n",
    "# sort values on \"DATUM_TIJD\"\n",
    "df = df.sort_values(\"DATUM_TIJD\")\n",
    "\n",
    "# .value returns time in nanoseconds, starting form unix time.\n",
    "# Get starting timestamp and convert this to '5 minutes'\n",
    "start_time = ns_to_5m(df[\"DATUM_TIJD\"].iloc[1].value)\n",
    "\n",
    "# Convert each DATETIME timestamp to a float value representing the amount of 5 minutes since start time\n",
    "df[\"DATUM_TIJD\"] = df['DATUM_TIJD'].apply(lambda x: ns_to_5m(x.value)-start_time)\n",
    "\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ceb2223c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>FIELD</th>\n",
       "      <th>DATUM_TIJD</th>\n",
       "      <th>M_VALUE_P</th>\n",
       "      <th>M_VALUE_Q</th>\n",
       "      <th>M_VALUE_I</th>\n",
       "      <th>BEDRIJFSSPANNING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tex</td>\n",
       "      <td>Tr1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nk</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dvd-RS</td>\n",
       "      <td>V309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.53</td>\n",
       "      <td>58.63</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dvd-RS</td>\n",
       "      <td>V301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.10</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dvd-RS</td>\n",
       "      <td>V307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.02</td>\n",
       "      <td>14.37</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023790</th>\n",
       "      <td>Ns</td>\n",
       "      <td>TR1</td>\n",
       "      <td>105119.0</td>\n",
       "      <td>-8.14</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1026.41</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023791</th>\n",
       "      <td>Nk</td>\n",
       "      <td>2.07</td>\n",
       "      <td>105119.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023792</th>\n",
       "      <td>Nk</td>\n",
       "      <td>2.08</td>\n",
       "      <td>105119.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>18.38</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023793</th>\n",
       "      <td>HFDP</td>\n",
       "      <td>V301</td>\n",
       "      <td>105119.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023794</th>\n",
       "      <td>HrvH</td>\n",
       "      <td>V105</td>\n",
       "      <td>105119.0</td>\n",
       "      <td>-3.13</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>84.82</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14023795 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         STATION FIELD  DATUM_TIJD  M_VALUE_P  M_VALUE_Q  M_VALUE_I  \\\n",
       "0            Tex   Tr1         0.0       0.00       0.00        NaN   \n",
       "1             Nk  2.11         0.0       0.00       0.00       0.56   \n",
       "2         Dvd-RS  V309         0.0       0.92       0.53      58.63   \n",
       "3         Dvd-RS  V301         0.0       0.23       0.01      12.10   \n",
       "4         Dvd-RS  V307         0.0       0.27       0.02      14.37   \n",
       "...          ...   ...         ...        ...        ...        ...   \n",
       "14023790      Ns   TR1    105119.0      -8.14       1.96    1026.41   \n",
       "14023791      Nk  2.07    105119.0       0.00       0.00       0.16   \n",
       "14023792      Nk  2.08    105119.0       0.29      -0.10      18.38   \n",
       "14023793    HFDP  V301    105119.0       0.01      -0.23       0.00   \n",
       "14023794    HrvH  V105    105119.0      -3.13      -0.37      84.82   \n",
       "\n",
       "          BEDRIJFSSPANNING  \n",
       "0                   0.0105  \n",
       "1                   0.0105  \n",
       "2                   0.0105  \n",
       "3                   0.0105  \n",
       "4                   0.0105  \n",
       "...                    ...  \n",
       "14023790            0.0105  \n",
       "14023791            0.0105  \n",
       "14023792            0.0105  \n",
       "14023793            0.0210  \n",
       "14023794            0.0210  \n",
       "\n",
       "[14023795 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ae2a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_P = df[\"M_VALUE_P\"].mean()\n",
    "mean_Q = df[\"M_VALUE_Q\"].mean()\n",
    "mean_I = df[\"M_VALUE_I\"].mean()\n",
    "df = fill_nan(df, mean_P, mean_Q, mean_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dcdef1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>FIELD</th>\n",
       "      <th>DATUM_TIJD</th>\n",
       "      <th>M_VALUE_P</th>\n",
       "      <th>M_VALUE_Q</th>\n",
       "      <th>M_VALUE_I</th>\n",
       "      <th>BEDRIJFSSPANNING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tex</td>\n",
       "      <td>Tr1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nk</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dvd-RS</td>\n",
       "      <td>V309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.53</td>\n",
       "      <td>58.63</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dvd-RS</td>\n",
       "      <td>V301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.10</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dvd-RS</td>\n",
       "      <td>V307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.02</td>\n",
       "      <td>14.37</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023790</th>\n",
       "      <td>Ns</td>\n",
       "      <td>TR1</td>\n",
       "      <td>105119.0</td>\n",
       "      <td>-8.14</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1026.41</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023791</th>\n",
       "      <td>Nk</td>\n",
       "      <td>2.07</td>\n",
       "      <td>105119.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023792</th>\n",
       "      <td>Nk</td>\n",
       "      <td>2.08</td>\n",
       "      <td>105119.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>18.38</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023793</th>\n",
       "      <td>HFDP</td>\n",
       "      <td>V301</td>\n",
       "      <td>105119.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023794</th>\n",
       "      <td>HrvH</td>\n",
       "      <td>V105</td>\n",
       "      <td>105119.0</td>\n",
       "      <td>-3.13</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>84.82</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14023795 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         STATION FIELD  DATUM_TIJD  M_VALUE_P  M_VALUE_Q  M_VALUE_I  \\\n",
       "0            Tex   Tr1         0.0       0.00       0.00       0.00   \n",
       "1             Nk  2.11         0.0       0.00       0.00       0.56   \n",
       "2         Dvd-RS  V309         0.0       0.92       0.53      58.63   \n",
       "3         Dvd-RS  V301         0.0       0.23       0.01      12.10   \n",
       "4         Dvd-RS  V307         0.0       0.27       0.02      14.37   \n",
       "...          ...   ...         ...        ...        ...        ...   \n",
       "14023790      Ns   TR1    105119.0      -8.14       1.96    1026.41   \n",
       "14023791      Nk  2.07    105119.0       0.00       0.00       0.16   \n",
       "14023792      Nk  2.08    105119.0       0.29      -0.10      18.38   \n",
       "14023793    HFDP  V301    105119.0       0.01      -0.23       0.00   \n",
       "14023794    HrvH  V105    105119.0      -3.13      -0.37      84.82   \n",
       "\n",
       "          BEDRIJFSSPANNING  \n",
       "0                   0.0105  \n",
       "1                   0.0105  \n",
       "2                   0.0105  \n",
       "3                   0.0105  \n",
       "4                   0.0105  \n",
       "...                    ...  \n",
       "14023790            0.0105  \n",
       "14023791            0.0105  \n",
       "14023792            0.0105  \n",
       "14023793            0.0210  \n",
       "14023794            0.0210  \n",
       "\n",
       "[14023795 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b73060c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = df[df[\"IN_UITGAAND\"].notna()]\n",
    "\n",
    "# df_x = df[[\"STATION\", \"FIELD\", \"DATUM_TIJD\", \"BEDRIJFSSPANNING\", \"IN_UITGAAND\", \"M_VALUE_I\"]]\n",
    "df_x = df[[\"STATION\", \"FIELD\", \"DATUM_TIJD\", \"BEDRIJFSSPANNING\", \"M_VALUE_I\"]]\n",
    "df_y = df[[\"STATION\", \"FIELD\", \"DATUM_TIJD\", \"M_VALUE_P\", \"M_VALUE_Q\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b04c7ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    df: pandas dataframe, amount_of_lag: int\n",
    "    Adds amount_of_lag lagged columns to the dataframe df,\n",
    "    such that each lagged column holds the field values from a previous timestamp.\n",
    "    It is possible to create leading columns instead of lagging columns by passing\n",
    "    amount_of_lag a negative value.\n",
    "\n",
    "'''\n",
    "def add_lag(df, amount_of_lag):\n",
    "    lst = []\n",
    "    \n",
    "    for station in df[\"STATION\"].unique():\n",
    "        temp_station_df = df[df[\"STATION\"] == station].copy(deep=True)\n",
    "        \n",
    "        for field in temp_station_df[\"FIELD\"].unique():\n",
    "            temp_field_df = temp_station_df[temp_station_df[\"FIELD\"] == field].copy(deep=True)\n",
    "            \n",
    "            for lag in range(1,amount_of_lag):\n",
    "                temp_field_df[\"lag_%s\" % (lag)] = temp_field_df[\"M_VALUE_I\"].shift(lag)\n",
    "\n",
    "            lst.append(temp_field_df.copy(deep=True))\n",
    "            lagged_df = pd.concat(lst)\n",
    "           \n",
    "    return lagged_df\n",
    "\n",
    "\n",
    "df_x = add_lag(df_x, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b4fbb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>FIELD</th>\n",
       "      <th>DATUM_TIJD</th>\n",
       "      <th>BEDRIJFSSPANNING</th>\n",
       "      <th>M_VALUE_I</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_8</th>\n",
       "      <th>lag_9</th>\n",
       "      <th>lag_10</th>\n",
       "      <th>lag_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tex</td>\n",
       "      <td>Tr1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Tex</td>\n",
       "      <td>Tr1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>Tex</td>\n",
       "      <td>Tr1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Tex</td>\n",
       "      <td>Tr1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>Tex</td>\n",
       "      <td>Tr1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023194</th>\n",
       "      <td>Lw</td>\n",
       "      <td>INSTAL1</td>\n",
       "      <td>105115.0</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>62.470628</td>\n",
       "      <td>61.484648</td>\n",
       "      <td>60.960535</td>\n",
       "      <td>60.323847</td>\n",
       "      <td>59.439029</td>\n",
       "      <td>58.776076</td>\n",
       "      <td>58.497215</td>\n",
       "      <td>57.222672</td>\n",
       "      <td>55.735906</td>\n",
       "      <td>57.342389</td>\n",
       "      <td>53.629411</td>\n",
       "      <td>54.951889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023316</th>\n",
       "      <td>Lw</td>\n",
       "      <td>INSTAL1</td>\n",
       "      <td>105116.0</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>63.444266</td>\n",
       "      <td>62.470628</td>\n",
       "      <td>61.484648</td>\n",
       "      <td>60.960535</td>\n",
       "      <td>60.323847</td>\n",
       "      <td>59.439029</td>\n",
       "      <td>58.776076</td>\n",
       "      <td>58.497215</td>\n",
       "      <td>57.222672</td>\n",
       "      <td>55.735906</td>\n",
       "      <td>57.342389</td>\n",
       "      <td>53.629411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023463</th>\n",
       "      <td>Lw</td>\n",
       "      <td>INSTAL1</td>\n",
       "      <td>105117.0</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>63.478481</td>\n",
       "      <td>63.444266</td>\n",
       "      <td>62.470628</td>\n",
       "      <td>61.484648</td>\n",
       "      <td>60.960535</td>\n",
       "      <td>60.323847</td>\n",
       "      <td>59.439029</td>\n",
       "      <td>58.776076</td>\n",
       "      <td>58.497215</td>\n",
       "      <td>57.222672</td>\n",
       "      <td>55.735906</td>\n",
       "      <td>57.342389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023559</th>\n",
       "      <td>Lw</td>\n",
       "      <td>INSTAL1</td>\n",
       "      <td>105118.0</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>62.741949</td>\n",
       "      <td>63.478481</td>\n",
       "      <td>63.444266</td>\n",
       "      <td>62.470628</td>\n",
       "      <td>61.484648</td>\n",
       "      <td>60.960535</td>\n",
       "      <td>60.323847</td>\n",
       "      <td>59.439029</td>\n",
       "      <td>58.776076</td>\n",
       "      <td>58.497215</td>\n",
       "      <td>57.222672</td>\n",
       "      <td>55.735906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14023789</th>\n",
       "      <td>Lw</td>\n",
       "      <td>INSTAL1</td>\n",
       "      <td>105119.0</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>61.534243</td>\n",
       "      <td>62.741949</td>\n",
       "      <td>63.478481</td>\n",
       "      <td>63.444266</td>\n",
       "      <td>62.470628</td>\n",
       "      <td>61.484648</td>\n",
       "      <td>60.960535</td>\n",
       "      <td>60.323847</td>\n",
       "      <td>59.439029</td>\n",
       "      <td>58.776076</td>\n",
       "      <td>58.497215</td>\n",
       "      <td>57.222672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14023795 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         STATION    FIELD  DATUM_TIJD  BEDRIJFSSPANNING  M_VALUE_I      lag_1  \\\n",
       "0            Tex      Tr1         0.0            0.0105   0.000000        NaN   \n",
       "183          Tex      Tr1         1.0            0.0105   0.000000   0.000000   \n",
       "359          Tex      Tr1         2.0            0.0105   0.000000   0.000000   \n",
       "501          Tex      Tr1         3.0            0.0105   0.000000   0.000000   \n",
       "609          Tex      Tr1         4.0            0.0105   0.000000   0.000000   \n",
       "...          ...      ...         ...               ...        ...        ...   \n",
       "14023194      Lw  INSTAL1    105115.0            0.0105  62.470628  61.484648   \n",
       "14023316      Lw  INSTAL1    105116.0            0.0105  63.444266  62.470628   \n",
       "14023463      Lw  INSTAL1    105117.0            0.0105  63.478481  63.444266   \n",
       "14023559      Lw  INSTAL1    105118.0            0.0105  62.741949  63.478481   \n",
       "14023789      Lw  INSTAL1    105119.0            0.0105  61.534243  62.741949   \n",
       "\n",
       "              lag_2      lag_3      lag_4      lag_5      lag_6      lag_7  \\\n",
       "0               NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "183             NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "359        0.000000        NaN        NaN        NaN        NaN        NaN   \n",
       "501        0.000000   0.000000        NaN        NaN        NaN        NaN   \n",
       "609        0.000000   0.000000   0.000000        NaN        NaN        NaN   \n",
       "...             ...        ...        ...        ...        ...        ...   \n",
       "14023194  60.960535  60.323847  59.439029  58.776076  58.497215  57.222672   \n",
       "14023316  61.484648  60.960535  60.323847  59.439029  58.776076  58.497215   \n",
       "14023463  62.470628  61.484648  60.960535  60.323847  59.439029  58.776076   \n",
       "14023559  63.444266  62.470628  61.484648  60.960535  60.323847  59.439029   \n",
       "14023789  63.478481  63.444266  62.470628  61.484648  60.960535  60.323847   \n",
       "\n",
       "              lag_8      lag_9     lag_10     lag_11  \n",
       "0               NaN        NaN        NaN        NaN  \n",
       "183             NaN        NaN        NaN        NaN  \n",
       "359             NaN        NaN        NaN        NaN  \n",
       "501             NaN        NaN        NaN        NaN  \n",
       "609             NaN        NaN        NaN        NaN  \n",
       "...             ...        ...        ...        ...  \n",
       "14023194  55.735906  57.342389  53.629411  54.951889  \n",
       "14023316  57.222672  55.735906  57.342389  53.629411  \n",
       "14023463  58.497215  57.222672  55.735906  57.342389  \n",
       "14023559  58.776076  58.497215  57.222672  55.735906  \n",
       "14023789  59.439029  58.776076  58.497215  57.222672  \n",
       "\n",
       "[14023795 rows x 16 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7acba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the dead space, or the amount of 0s present in the dataset\n",
    "def calc_percentage_dead_space(Xs):\n",
    "    dead_space = np.zeros(len(Xs))\n",
    "    total = Xs[0].stack().value_counts().sum()\n",
    "    for index, df in enumerate(Xs):\n",
    "        zeros = df.stack().value_counts()[0]\n",
    "        dead_space[index] = zeros/total\n",
    "    return dead_space\n",
    "\n",
    "\n",
    "\n",
    "# input - df: a Dataframe, chunkSize: the chunk size\n",
    "# output - a list of DataFrame\n",
    "# purpose - splits the DataFrame into smaller chunks\n",
    "def split_dataframe(df, chunk_size, limit): \n",
    "    chunks = list()\n",
    "    df = df[df[\"DATUM_TIJD\"] <= limit]\n",
    "    entries_per_5_min = df[df[\"DATUM_TIJD\"]==0].shape[0]\n",
    "    print(chunk_size)\n",
    "    num_chunks = len(df) // (chunk_size*entries_per_5_min) + 1\n",
    "    print(num_chunks)\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return chunks\n",
    "    \n",
    "\n",
    "# splits the data on stations, creating a data subset for each station\n",
    "# amount of data taken from each station specified with weeks\n",
    "# limit is the amount of samples desired per split. Useful for quick test runs\n",
    "def split_on_stations(df_IU, df_PQ, weeks, limit=0):\n",
    "    if limit == 0:\n",
    "        limit = df_IU.shape[0]\n",
    "    \n",
    "    df_IU = df_IU[df_IU[\"DATUM_TIJD\"] <= limit]\n",
    "    df_PQ = df_PQ[df_PQ[\"DATUM_TIJD\"] <= limit]\n",
    "    \n",
    "    df_IU = reduce_timescale(df_IU, weeks)\n",
    "    df_PQ = reduce_timescale(df_PQ, weeks)\n",
    "    \n",
    "    stations = df_IU[\"STATION\"].unique()\n",
    "\n",
    "    dfs_IU = []\n",
    "    dfs_PQ = []\n",
    "\n",
    "    for station in stations:\n",
    "        temp_IU = df_IU[df_IU[\"STATION\"]==station]\n",
    "        temp_PQ = df_PQ[df_PQ[\"STATION\"]==station]\n",
    "\n",
    "        del temp_PQ[\"DATUM_TIJD\"]\n",
    "        del temp_IU[\"STATION\"], temp_PQ[\"STATION\"]\n",
    "        del temp_IU[\"FIELD\"], temp_PQ[\"FIELD\"]\n",
    "        \n",
    "        temp_PQ#.reset_index(drop = True, inplace = True)\n",
    "        temp_IU#.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        dfs_IU.append(temp_IU)\n",
    "        dfs_PQ.append(temp_PQ)\n",
    "    \n",
    "    return dfs_IU, dfs_PQ\n",
    "\n",
    "\n",
    "# splits the data in equal parts of depending on the desired amount of weeks\n",
    "# limit is the amount of samples desired per split. Useful for quick test runs\n",
    "def split_on_weeks(df_IU, df_PQ, weeks, limit=0):   \n",
    "    if limit == 0:\n",
    "        limit = df_IU.shape[0]\n",
    "    \n",
    "    dfs_IU = split_dataframe(df_IU, weeks_to_5_mins(weeks), limit)\n",
    "    dfs_PQ = split_dataframe(df_PQ, weeks_to_5_mins(weeks), limit)\n",
    "    \n",
    "    for index in range(len(dfs_IU)):\n",
    "        temp_IU = dfs_IU[index]#.reset_index(drop=True)\n",
    "        temp_PQ = dfs_PQ[index]#.reset_index(drop=True)\n",
    "        \n",
    "        del temp_PQ[\"DATUM_TIJD\"]\n",
    "        del temp_IU[\"STATION\"], temp_PQ[\"STATION\"]\n",
    "        del temp_IU[\"FIELD\"], temp_PQ[\"FIELD\"]\n",
    "        \n",
    "        dfs_IU[index] = temp_IU\n",
    "        dfs_PQ[index] = temp_PQ\n",
    "    \n",
    "    return dfs_IU, dfs_PQ\n",
    "    \n",
    "\n",
    "# performs cross validation on the split datasets of Xs and ys.\n",
    "# Metrics preserved are sign accuracy and mse, which are returned in a 2D result matrix\n",
    "def cross_validation(Xs, ys):\n",
    "    matrix = np.zeros((len(ys),len(ys),2))\n",
    "    alpha = 10\n",
    "    for x_index, X_train in enumerate(Xs):\n",
    "        y_train = ys[x_index]\n",
    "        for y_index, y_test in enumerate(ys):\n",
    "            print(\"X: {0}, Y: {1}\".format(x_index, y_index))\n",
    "            X_test = Xs[y_index]\n",
    "            df_predict = GaussianProcess_regression(X_train, y_train, X_test)\n",
    "            \n",
    "            P,_ = predict_sign(df_predict, y_test)\n",
    "            mse = mean_squared_error(y_test, df_predict)\n",
    "            \n",
    "            matrix[x_index, y_index, 0] = P\n",
    "            matrix[x_index, y_index, 1] = mse\n",
    "            \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49a82587",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.sort_index(inplace=True)\n",
    "df_x.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfe2330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce timescale\n",
    "\n",
    "# calculates the amount of 5 minutes present in an amount of weeks\n",
    "def weeks_to_5_mins(weeks):\n",
    "    return 12*24*7*weeks\n",
    "\n",
    "# reduce the timescale of the data set to be less than the specified amount of weeks\n",
    "def reduce_timescale(df, weeks):\n",
    "    weeks = weeks_to_5_mins(weeks)\n",
    "    df = df[df[\"DATUM_TIJD\"] <= weeks]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "baba8438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = 10\n",
    "def GaussianProcess_regression(X_train, y_train, X_test, alpha=10):\n",
    "    model = GaussianProcessRegressor(alpha = alpha)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predict = model.predict(X_test)\n",
    "    df_predict = pd.DataFrame(predict, columns = y_train.columns, dtype = float)\n",
    "    return df_predict\n",
    "\n",
    "\n",
    "def XGboost_regression(X_train, y_train, X_test):\n",
    "    model = XGBRegressor(objective='reg:squarederror')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predict = model.predict(X_test)\n",
    "    df_predict = pd.DataFrame(predict, columns = y_train.columns, dtype = float)\n",
    "    return df_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6091c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    df_predict: pandas dataframe, y_test: pandas dataframe\n",
    "    Compares the dataframe of predictions with the dataframe containing the true\n",
    "    values. Computes the accuracy based sign prediction (+ or -) of P and Q and returns it.\n",
    "'''\n",
    "\n",
    "def predict_sign(df_predict, y_test):\n",
    "    df_sign = df_predict.copy()\n",
    "    df_y_sign = y_test.copy()\n",
    "    for col in df_sign.columns:\n",
    "        df_sign[col] = df_sign[col].apply(lambda x: -1 if x<0 else 1)\n",
    "        df_y_sign[col] = df_y_sign[col].apply(lambda x: -1 if x<0 else 1)\n",
    "\n",
    "    df_new_sign = df_sign == df_y_sign\n",
    "    \n",
    "    field_accuracies = []\n",
    "    for col in df_new_sign.columns:\n",
    "        field_accuracies.append(df_new_sign[col].value_counts(normalize=True).values[0])\n",
    "\n",
    "    P_accuracies = field_accuracies[::2]\n",
    "    Q_accuracies = field_accuracies[1::2]\n",
    "    \n",
    "    P_avg = sum(P_accuracies)/len(P_accuracies)\n",
    "    Q_avg = sum(Q_accuracies)/len(Q_accuracies)\n",
    "    \n",
    "    return P_avg, Q_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6128d408",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "\n",
    "cross validation is done by selecting the train-test split (either split_on_weeks or split_on_stations) and then within the function cross_validation to change your machine learning model (either XGboost_regression or GaussianProcess_regression). This will perform cross validation and save the results of each train-test combination in a result matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e224f46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 0, Y: 0\n",
      "X: 0, Y: 1\n",
      "X: 0, Y: 2\n",
      "X: 0, Y: 3\n",
      "X: 0, Y: 4\n",
      "X: 0, Y: 5\n",
      "X: 0, Y: 6\n",
      "X: 0, Y: 7\n",
      "X: 0, Y: 8\n",
      "X: 0, Y: 9\n",
      "X: 1, Y: 0\n",
      "X: 1, Y: 1\n",
      "X: 1, Y: 2\n",
      "X: 1, Y: 3\n",
      "X: 1, Y: 4\n",
      "X: 1, Y: 5\n",
      "X: 1, Y: 6\n",
      "X: 1, Y: 7\n",
      "X: 1, Y: 8\n",
      "X: 1, Y: 9\n",
      "X: 2, Y: 0\n",
      "X: 2, Y: 1\n",
      "X: 2, Y: 2\n",
      "X: 2, Y: 3\n",
      "X: 2, Y: 4\n",
      "X: 2, Y: 5\n",
      "X: 2, Y: 6\n",
      "X: 2, Y: 7\n",
      "X: 2, Y: 8\n",
      "X: 2, Y: 9\n",
      "X: 3, Y: 0\n",
      "X: 3, Y: 1\n",
      "X: 3, Y: 2\n",
      "X: 3, Y: 3\n",
      "X: 3, Y: 4\n",
      "X: 3, Y: 5\n",
      "X: 3, Y: 6\n",
      "X: 3, Y: 7\n",
      "X: 3, Y: 8\n",
      "X: 3, Y: 9\n",
      "X: 4, Y: 0\n",
      "X: 4, Y: 1\n",
      "X: 4, Y: 2\n",
      "X: 4, Y: 3\n",
      "X: 4, Y: 4\n",
      "X: 4, Y: 5\n",
      "X: 4, Y: 6\n",
      "X: 4, Y: 7\n",
      "X: 4, Y: 8\n",
      "X: 4, Y: 9\n",
      "X: 5, Y: 0\n",
      "X: 5, Y: 1\n",
      "X: 5, Y: 2\n",
      "X: 5, Y: 3\n",
      "X: 5, Y: 4\n",
      "X: 5, Y: 5\n",
      "X: 5, Y: 6\n",
      "X: 5, Y: 7\n",
      "X: 5, Y: 8\n",
      "X: 5, Y: 9\n",
      "X: 6, Y: 0\n",
      "X: 6, Y: 1\n",
      "X: 6, Y: 2\n",
      "X: 6, Y: 3\n",
      "X: 6, Y: 4\n",
      "X: 6, Y: 5\n",
      "X: 6, Y: 6\n",
      "X: 6, Y: 7\n",
      "X: 6, Y: 8\n",
      "X: 6, Y: 9\n",
      "X: 7, Y: 0\n",
      "X: 7, Y: 1\n",
      "X: 7, Y: 2\n",
      "X: 7, Y: 3\n",
      "X: 7, Y: 4\n",
      "X: 7, Y: 5\n",
      "X: 7, Y: 6\n",
      "X: 7, Y: 7\n",
      "X: 7, Y: 8\n",
      "X: 7, Y: 9\n",
      "X: 8, Y: 0\n",
      "X: 8, Y: 1\n",
      "X: 8, Y: 2\n",
      "X: 8, Y: 3\n",
      "X: 8, Y: 4\n",
      "X: 8, Y: 5\n",
      "X: 8, Y: 6\n",
      "X: 8, Y: 7\n",
      "X: 8, Y: 8\n",
      "X: 8, Y: 9\n",
      "X: 9, Y: 0\n",
      "X: 9, Y: 1\n",
      "X: 9, Y: 2\n",
      "X: 9, Y: 3\n",
      "X: 9, Y: 4\n",
      "X: 9, Y: 5\n",
      "X: 9, Y: 6\n",
      "X: 9, Y: 7\n",
      "X: 9, Y: 8\n",
      "X: 9, Y: 9\n",
      "Time ran:  1703.9747066497803\n"
     ]
    }
   ],
   "source": [
    "weeks = 2\n",
    "st = time.time()\n",
    "limit = 0\n",
    "\n",
    "Xs, ys = split_on_weeks(df_x, df_y, weeks, limit)\n",
    "matrix = cross_validation(Xs, ys)\n",
    "\n",
    "et = time.time()\n",
    "print(\"Time ran: \", et - st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd559bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trained_on_0</th>\n",
       "      <th>trained_on_1</th>\n",
       "      <th>trained_on_2</th>\n",
       "      <th>trained_on_3</th>\n",
       "      <th>trained_on_4</th>\n",
       "      <th>trained_on_5</th>\n",
       "      <th>trained_on_6</th>\n",
       "      <th>trained_on_7</th>\n",
       "      <th>trained_on_8</th>\n",
       "      <th>trained_on_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tested_on_0</th>\n",
       "      <td>0.939356</td>\n",
       "      <td>0.738416</td>\n",
       "      <td>0.521516</td>\n",
       "      <td>0.748477</td>\n",
       "      <td>0.501089</td>\n",
       "      <td>0.874794</td>\n",
       "      <td>0.665017</td>\n",
       "      <td>0.796535</td>\n",
       "      <td>0.622153</td>\n",
       "      <td>0.952970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_1</th>\n",
       "      <td>0.689769</td>\n",
       "      <td>0.840891</td>\n",
       "      <td>0.846915</td>\n",
       "      <td>0.551980</td>\n",
       "      <td>0.740594</td>\n",
       "      <td>0.557756</td>\n",
       "      <td>0.662541</td>\n",
       "      <td>0.643564</td>\n",
       "      <td>0.733045</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_2</th>\n",
       "      <td>0.686469</td>\n",
       "      <td>0.850891</td>\n",
       "      <td>0.939452</td>\n",
       "      <td>0.548743</td>\n",
       "      <td>0.756535</td>\n",
       "      <td>0.596122</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.652970</td>\n",
       "      <td>0.741213</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_3</th>\n",
       "      <td>0.705171</td>\n",
       "      <td>0.879010</td>\n",
       "      <td>0.863861</td>\n",
       "      <td>0.890137</td>\n",
       "      <td>0.668713</td>\n",
       "      <td>0.718028</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.651238</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_4</th>\n",
       "      <td>0.636139</td>\n",
       "      <td>0.663564</td>\n",
       "      <td>0.724105</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.954455</td>\n",
       "      <td>0.799917</td>\n",
       "      <td>0.660066</td>\n",
       "      <td>0.561881</td>\n",
       "      <td>0.660644</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_5</th>\n",
       "      <td>0.773927</td>\n",
       "      <td>0.898317</td>\n",
       "      <td>0.818355</td>\n",
       "      <td>0.697639</td>\n",
       "      <td>0.626040</td>\n",
       "      <td>0.934818</td>\n",
       "      <td>0.593234</td>\n",
       "      <td>0.674257</td>\n",
       "      <td>0.745050</td>\n",
       "      <td>0.952970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_6</th>\n",
       "      <td>0.606436</td>\n",
       "      <td>0.655545</td>\n",
       "      <td>0.629094</td>\n",
       "      <td>0.681835</td>\n",
       "      <td>0.539010</td>\n",
       "      <td>0.579414</td>\n",
       "      <td>0.997525</td>\n",
       "      <td>0.833168</td>\n",
       "      <td>0.510396</td>\n",
       "      <td>0.634901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_7</th>\n",
       "      <td>0.642739</td>\n",
       "      <td>0.833861</td>\n",
       "      <td>0.898324</td>\n",
       "      <td>0.734577</td>\n",
       "      <td>0.588614</td>\n",
       "      <td>0.873969</td>\n",
       "      <td>0.646865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.781064</td>\n",
       "      <td>0.543317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_8</th>\n",
       "      <td>0.531903</td>\n",
       "      <td>0.602277</td>\n",
       "      <td>0.777609</td>\n",
       "      <td>0.712300</td>\n",
       "      <td>0.804455</td>\n",
       "      <td>0.801155</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.730693</td>\n",
       "      <td>0.790223</td>\n",
       "      <td>0.795792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested_on_9</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.999208</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.639604</td>\n",
       "      <td>0.875825</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             trained_on_0  trained_on_1  trained_on_2  trained_on_3  \\\n",
       "tested_on_0      0.939356      0.738416      0.521516      0.748477   \n",
       "tested_on_1      0.689769      0.840891      0.846915      0.551980   \n",
       "tested_on_2      0.686469      0.850891      0.939452      0.548743   \n",
       "tested_on_3      0.705171      0.879010      0.863861      0.890137   \n",
       "tested_on_4      0.636139      0.663564      0.724105      0.692308   \n",
       "tested_on_5      0.773927      0.898317      0.818355      0.697639   \n",
       "tested_on_6      0.606436      0.655545      0.629094      0.681835   \n",
       "tested_on_7      0.642739      0.833861      0.898324      0.734577   \n",
       "tested_on_8      0.531903      0.602277      0.777609      0.712300   \n",
       "tested_on_9      0.777778      0.999208      0.923077      0.769231   \n",
       "\n",
       "             trained_on_4  trained_on_5  trained_on_6  trained_on_7  \\\n",
       "tested_on_0      0.501089      0.874794      0.665017      0.796535   \n",
       "tested_on_1      0.740594      0.557756      0.662541      0.643564   \n",
       "tested_on_2      0.756535      0.596122      0.666667      0.652970   \n",
       "tested_on_3      0.668713      0.718028      0.729373      0.650000   \n",
       "tested_on_4      0.954455      0.799917      0.660066      0.561881   \n",
       "tested_on_5      0.626040      0.934818      0.593234      0.674257   \n",
       "tested_on_6      0.539010      0.579414      0.997525      0.833168   \n",
       "tested_on_7      0.588614      0.873969      0.646865      1.000000   \n",
       "tested_on_8      0.804455      0.801155      0.666667      0.730693   \n",
       "tested_on_9      0.639604      0.875825      0.666667      0.800000   \n",
       "\n",
       "             trained_on_8  trained_on_9  \n",
       "tested_on_0      0.622153      0.952970  \n",
       "tested_on_1      0.733045      1.000000  \n",
       "tested_on_2      0.741213      1.000000  \n",
       "tested_on_3      0.651238      1.000000  \n",
       "tested_on_4      0.660644      1.000000  \n",
       "tested_on_5      0.745050      0.952970  \n",
       "tested_on_6      0.510396      0.634901  \n",
       "tested_on_7      0.781064      0.543317  \n",
       "tested_on_8      0.790223      0.795792  \n",
       "tested_on_9      0.800000      1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add column and row names for crossvalidation\n",
    "lst = np.arange(matrix.shape[0])\n",
    "cols = [\"trained_on_\" + str(number) for number in lst]\n",
    "rows = [\"tested_on_\" + str(number) for number in lst]\n",
    "\n",
    "pd_crossval_stations = pd.DataFrame(matrix[:,:,0].T, index = rows, columns = cols,dtype = float)\n",
    "pd_crossval_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9da1ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric 0 = sign accuracy, metric 1 = mse\n",
    "'''\n",
    "    matrix: np.array, metric: int, file_name: string\n",
    "    Exports the specific metrics of the crossvalidation to a .feater file with.\n",
    "    Matrix stores the validation results. Metric = 0 returns sign accuracy and metric = 1 the mse.\n",
    "'''\n",
    "def export_results(matrix, metric, file_name):\n",
    "    # # add column and row names for crossvalidation\n",
    "    lst = np.arange(matrix.shape[0])\n",
    "    cols = [\"trained_on_\" + str(number) for number in lst]\n",
    "    rows = [\"tested_on_\" + str(number) for number in lst]\n",
    "    \n",
    "    pd_crossval_stations = pd.DataFrame(matrix[:,:,metric].T, index = rows, columns = cols,dtype = float)\n",
    "    dead_space = calc_percentage_dead_space(Xs)\n",
    "\n",
    "    pd_crossval_stations[\"dead_space\"] = dead_space\n",
    "    pd_crossval_weeks = pd_crossval_stations.reset_index()\n",
    "    pd_crossval_weeks.to_feather(\"results/\"+file_name)\n",
    "\n",
    "    return pd_crossval_weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef608ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>trained_on_0</th>\n",
       "      <th>trained_on_1</th>\n",
       "      <th>trained_on_2</th>\n",
       "      <th>trained_on_3</th>\n",
       "      <th>trained_on_4</th>\n",
       "      <th>trained_on_5</th>\n",
       "      <th>trained_on_6</th>\n",
       "      <th>trained_on_7</th>\n",
       "      <th>trained_on_8</th>\n",
       "      <th>trained_on_9</th>\n",
       "      <th>dead_space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tested_on_0</td>\n",
       "      <td>0.939356</td>\n",
       "      <td>0.738416</td>\n",
       "      <td>0.521516</td>\n",
       "      <td>0.748477</td>\n",
       "      <td>0.501089</td>\n",
       "      <td>0.874794</td>\n",
       "      <td>0.665017</td>\n",
       "      <td>0.796535</td>\n",
       "      <td>0.622153</td>\n",
       "      <td>0.952970</td>\n",
       "      <td>0.152758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tested_on_1</td>\n",
       "      <td>0.689769</td>\n",
       "      <td>0.840891</td>\n",
       "      <td>0.846915</td>\n",
       "      <td>0.551980</td>\n",
       "      <td>0.740594</td>\n",
       "      <td>0.557756</td>\n",
       "      <td>0.662541</td>\n",
       "      <td>0.643564</td>\n",
       "      <td>0.733045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.157365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tested_on_2</td>\n",
       "      <td>0.686469</td>\n",
       "      <td>0.850891</td>\n",
       "      <td>0.939452</td>\n",
       "      <td>0.548743</td>\n",
       "      <td>0.756535</td>\n",
       "      <td>0.596122</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.652970</td>\n",
       "      <td>0.741213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tested_on_3</td>\n",
       "      <td>0.705171</td>\n",
       "      <td>0.879010</td>\n",
       "      <td>0.863861</td>\n",
       "      <td>0.890137</td>\n",
       "      <td>0.668713</td>\n",
       "      <td>0.718028</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.651238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tested_on_4</td>\n",
       "      <td>0.636139</td>\n",
       "      <td>0.663564</td>\n",
       "      <td>0.724105</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.954455</td>\n",
       "      <td>0.799917</td>\n",
       "      <td>0.660066</td>\n",
       "      <td>0.561881</td>\n",
       "      <td>0.660644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.348637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tested_on_5</td>\n",
       "      <td>0.773927</td>\n",
       "      <td>0.898317</td>\n",
       "      <td>0.818355</td>\n",
       "      <td>0.697639</td>\n",
       "      <td>0.626040</td>\n",
       "      <td>0.934818</td>\n",
       "      <td>0.593234</td>\n",
       "      <td>0.674257</td>\n",
       "      <td>0.745050</td>\n",
       "      <td>0.952970</td>\n",
       "      <td>0.397631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tested_on_6</td>\n",
       "      <td>0.606436</td>\n",
       "      <td>0.655545</td>\n",
       "      <td>0.629094</td>\n",
       "      <td>0.681835</td>\n",
       "      <td>0.539010</td>\n",
       "      <td>0.579414</td>\n",
       "      <td>0.997525</td>\n",
       "      <td>0.833168</td>\n",
       "      <td>0.510396</td>\n",
       "      <td>0.634901</td>\n",
       "      <td>0.001974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tested_on_7</td>\n",
       "      <td>0.642739</td>\n",
       "      <td>0.833861</td>\n",
       "      <td>0.898324</td>\n",
       "      <td>0.734577</td>\n",
       "      <td>0.588614</td>\n",
       "      <td>0.873969</td>\n",
       "      <td>0.646865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.781064</td>\n",
       "      <td>0.543317</td>\n",
       "      <td>0.050261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tested_on_8</td>\n",
       "      <td>0.531903</td>\n",
       "      <td>0.602277</td>\n",
       "      <td>0.777609</td>\n",
       "      <td>0.712300</td>\n",
       "      <td>0.804455</td>\n",
       "      <td>0.801155</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.730693</td>\n",
       "      <td>0.790223</td>\n",
       "      <td>0.795792</td>\n",
       "      <td>0.201045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tested_on_9</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.999208</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.639604</td>\n",
       "      <td>0.875825</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  trained_on_0  trained_on_1  trained_on_2  trained_on_3  \\\n",
       "0  tested_on_0      0.939356      0.738416      0.521516      0.748477   \n",
       "1  tested_on_1      0.689769      0.840891      0.846915      0.551980   \n",
       "2  tested_on_2      0.686469      0.850891      0.939452      0.548743   \n",
       "3  tested_on_3      0.705171      0.879010      0.863861      0.890137   \n",
       "4  tested_on_4      0.636139      0.663564      0.724105      0.692308   \n",
       "5  tested_on_5      0.773927      0.898317      0.818355      0.697639   \n",
       "6  tested_on_6      0.606436      0.655545      0.629094      0.681835   \n",
       "7  tested_on_7      0.642739      0.833861      0.898324      0.734577   \n",
       "8  tested_on_8      0.531903      0.602277      0.777609      0.712300   \n",
       "9  tested_on_9      0.777778      0.999208      0.923077      0.769231   \n",
       "\n",
       "   trained_on_4  trained_on_5  trained_on_6  trained_on_7  trained_on_8  \\\n",
       "0      0.501089      0.874794      0.665017      0.796535      0.622153   \n",
       "1      0.740594      0.557756      0.662541      0.643564      0.733045   \n",
       "2      0.756535      0.596122      0.666667      0.652970      0.741213   \n",
       "3      0.668713      0.718028      0.729373      0.650000      0.651238   \n",
       "4      0.954455      0.799917      0.660066      0.561881      0.660644   \n",
       "5      0.626040      0.934818      0.593234      0.674257      0.745050   \n",
       "6      0.539010      0.579414      0.997525      0.833168      0.510396   \n",
       "7      0.588614      0.873969      0.646865      1.000000      0.781064   \n",
       "8      0.804455      0.801155      0.666667      0.730693      0.790223   \n",
       "9      0.639604      0.875825      0.666667      0.800000      0.800000   \n",
       "\n",
       "   trained_on_9  dead_space  \n",
       "0      0.952970    0.152758  \n",
       "1      1.000000    0.157365  \n",
       "2      1.000000    0.087351  \n",
       "3      1.000000    0.290026  \n",
       "4      1.000000    0.348637  \n",
       "5      0.952970    0.397631  \n",
       "6      0.634901    0.001974  \n",
       "7      0.543317    0.050261  \n",
       "8      0.795792    0.201045  \n",
       "9      1.000000    0.001316  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_accuracy = \"gp_station_single_field_crossval_accuracy.feather\"\n",
    "\n",
    "export_results(matrix, 0, file_name_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a026645e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>trained_on_0</th>\n",
       "      <th>trained_on_1</th>\n",
       "      <th>trained_on_2</th>\n",
       "      <th>trained_on_3</th>\n",
       "      <th>trained_on_4</th>\n",
       "      <th>trained_on_5</th>\n",
       "      <th>trained_on_6</th>\n",
       "      <th>trained_on_7</th>\n",
       "      <th>trained_on_8</th>\n",
       "      <th>trained_on_9</th>\n",
       "      <th>dead_space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tested_on_0</td>\n",
       "      <td>2.430910</td>\n",
       "      <td>5.059704</td>\n",
       "      <td>1.486741</td>\n",
       "      <td>1.646578</td>\n",
       "      <td>2.339413</td>\n",
       "      <td>5.330394</td>\n",
       "      <td>93.630222</td>\n",
       "      <td>12.866848</td>\n",
       "      <td>10.674727</td>\n",
       "      <td>116.793449</td>\n",
       "      <td>0.152758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tested_on_1</td>\n",
       "      <td>3.284367</td>\n",
       "      <td>3.830890</td>\n",
       "      <td>1.485882</td>\n",
       "      <td>1.646626</td>\n",
       "      <td>2.382576</td>\n",
       "      <td>5.330394</td>\n",
       "      <td>93.769929</td>\n",
       "      <td>12.852976</td>\n",
       "      <td>10.677602</td>\n",
       "      <td>116.775249</td>\n",
       "      <td>0.157365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tested_on_2</td>\n",
       "      <td>3.285033</td>\n",
       "      <td>5.055241</td>\n",
       "      <td>1.207248</td>\n",
       "      <td>1.646636</td>\n",
       "      <td>2.353106</td>\n",
       "      <td>5.330394</td>\n",
       "      <td>93.623672</td>\n",
       "      <td>12.851954</td>\n",
       "      <td>10.671304</td>\n",
       "      <td>116.794450</td>\n",
       "      <td>0.087351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tested_on_3</td>\n",
       "      <td>3.283032</td>\n",
       "      <td>5.058764</td>\n",
       "      <td>1.479241</td>\n",
       "      <td>1.329651</td>\n",
       "      <td>2.351463</td>\n",
       "      <td>5.330456</td>\n",
       "      <td>93.659032</td>\n",
       "      <td>12.852924</td>\n",
       "      <td>10.671982</td>\n",
       "      <td>116.794582</td>\n",
       "      <td>0.290026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tested_on_4</td>\n",
       "      <td>3.261536</td>\n",
       "      <td>5.076645</td>\n",
       "      <td>1.486560</td>\n",
       "      <td>1.647019</td>\n",
       "      <td>1.778517</td>\n",
       "      <td>5.332614</td>\n",
       "      <td>93.644452</td>\n",
       "      <td>12.861403</td>\n",
       "      <td>10.678176</td>\n",
       "      <td>116.757658</td>\n",
       "      <td>0.348637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tested_on_5</td>\n",
       "      <td>3.283068</td>\n",
       "      <td>5.058770</td>\n",
       "      <td>1.479235</td>\n",
       "      <td>1.646675</td>\n",
       "      <td>2.352099</td>\n",
       "      <td>4.163205</td>\n",
       "      <td>93.622021</td>\n",
       "      <td>12.852919</td>\n",
       "      <td>10.671816</td>\n",
       "      <td>116.794582</td>\n",
       "      <td>0.397631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tested_on_6</td>\n",
       "      <td>3.284776</td>\n",
       "      <td>5.076019</td>\n",
       "      <td>1.479896</td>\n",
       "      <td>1.659445</td>\n",
       "      <td>2.359245</td>\n",
       "      <td>5.330394</td>\n",
       "      <td>69.410820</td>\n",
       "      <td>12.857916</td>\n",
       "      <td>10.672186</td>\n",
       "      <td>116.795411</td>\n",
       "      <td>0.001974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tested_on_7</td>\n",
       "      <td>3.287488</td>\n",
       "      <td>5.058834</td>\n",
       "      <td>1.478967</td>\n",
       "      <td>1.646633</td>\n",
       "      <td>2.354886</td>\n",
       "      <td>5.330394</td>\n",
       "      <td>93.630730</td>\n",
       "      <td>9.679976</td>\n",
       "      <td>10.631824</td>\n",
       "      <td>116.938030</td>\n",
       "      <td>0.050261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tested_on_8</td>\n",
       "      <td>3.284162</td>\n",
       "      <td>5.057208</td>\n",
       "      <td>1.478370</td>\n",
       "      <td>1.646983</td>\n",
       "      <td>2.353927</td>\n",
       "      <td>5.330579</td>\n",
       "      <td>93.623639</td>\n",
       "      <td>12.697833</td>\n",
       "      <td>7.731250</td>\n",
       "      <td>116.925779</td>\n",
       "      <td>0.201045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tested_on_9</td>\n",
       "      <td>3.282953</td>\n",
       "      <td>5.057611</td>\n",
       "      <td>1.479198</td>\n",
       "      <td>1.646636</td>\n",
       "      <td>2.353566</td>\n",
       "      <td>5.330394</td>\n",
       "      <td>93.622564</td>\n",
       "      <td>12.909884</td>\n",
       "      <td>10.685709</td>\n",
       "      <td>89.676537</td>\n",
       "      <td>0.001316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  trained_on_0  trained_on_1  trained_on_2  trained_on_3  \\\n",
       "0  tested_on_0      2.430910      5.059704      1.486741      1.646578   \n",
       "1  tested_on_1      3.284367      3.830890      1.485882      1.646626   \n",
       "2  tested_on_2      3.285033      5.055241      1.207248      1.646636   \n",
       "3  tested_on_3      3.283032      5.058764      1.479241      1.329651   \n",
       "4  tested_on_4      3.261536      5.076645      1.486560      1.647019   \n",
       "5  tested_on_5      3.283068      5.058770      1.479235      1.646675   \n",
       "6  tested_on_6      3.284776      5.076019      1.479896      1.659445   \n",
       "7  tested_on_7      3.287488      5.058834      1.478967      1.646633   \n",
       "8  tested_on_8      3.284162      5.057208      1.478370      1.646983   \n",
       "9  tested_on_9      3.282953      5.057611      1.479198      1.646636   \n",
       "\n",
       "   trained_on_4  trained_on_5  trained_on_6  trained_on_7  trained_on_8  \\\n",
       "0      2.339413      5.330394     93.630222     12.866848     10.674727   \n",
       "1      2.382576      5.330394     93.769929     12.852976     10.677602   \n",
       "2      2.353106      5.330394     93.623672     12.851954     10.671304   \n",
       "3      2.351463      5.330456     93.659032     12.852924     10.671982   \n",
       "4      1.778517      5.332614     93.644452     12.861403     10.678176   \n",
       "5      2.352099      4.163205     93.622021     12.852919     10.671816   \n",
       "6      2.359245      5.330394     69.410820     12.857916     10.672186   \n",
       "7      2.354886      5.330394     93.630730      9.679976     10.631824   \n",
       "8      2.353927      5.330579     93.623639     12.697833      7.731250   \n",
       "9      2.353566      5.330394     93.622564     12.909884     10.685709   \n",
       "\n",
       "   trained_on_9  dead_space  \n",
       "0    116.793449    0.152758  \n",
       "1    116.775249    0.157365  \n",
       "2    116.794450    0.087351  \n",
       "3    116.794582    0.290026  \n",
       "4    116.757658    0.348637  \n",
       "5    116.794582    0.397631  \n",
       "6    116.795411    0.001974  \n",
       "7    116.938030    0.050261  \n",
       "8    116.925779    0.201045  \n",
       "9     89.676537    0.001316  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_mse = \"gp_station_single_field_crossval_mse.feather\"\n",
    "\n",
    "export_results(matrix, 1, file_name_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a539d84",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "Plotting specific train-test combinations for display purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20318b70",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 75.7 GiB for an array with shape (100800, 100800) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [40], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m     df_gp_predict \u001b[38;5;241m=\u001b[39m GaussianProcess_regression(x_train, y_train, x_test)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_xg_predict, df_gp_predict, y_test\n\u001b[1;32m---> 16\u001b[0m df_xg_predict, df_gp_predict, df_true_P \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_on_stations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_y\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [40], line 12\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(train_on, test_on, weeks, split_on, df_x, df_y)\u001b[0m\n\u001b[0;32m      9\u001b[0m     y_test \u001b[38;5;241m=\u001b[39m ys[test_on]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#     df_xg_predict = XGboost_regression(x_train, y_train, x_test)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     df_gp_predict \u001b[38;5;241m=\u001b[39m \u001b[43mGaussianProcess_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_xg_predict, df_gp_predict, y_test\n",
      "Cell \u001b[1;32mIn [30], line 66\u001b[0m, in \u001b[0;36mGaussianProcess_regression\u001b[1;34m(X_train, y_train, X_test, alpha)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mGaussianProcess_regression\u001b[39m(X_train, y_train, X_test, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m     65\u001b[0m     model \u001b[38;5;241m=\u001b[39m GaussianProcessRegressor(alpha \u001b[38;5;241m=\u001b[39m alpha)\n\u001b[1;32m---> 66\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     predict \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     69\u001b[0m     df_predict \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(predict, columns \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mcolumns, dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\alliander\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:314\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_marginal_likelihood_value_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mmin(lml_values)\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_marginal_likelihood_value_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_marginal_likelihood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# Precompute quantities required for predictions which are independent\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;66;03m# of actual query points\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# Alg. 2.1, page 19, line 2 -> L = cholesky(K + sigma^2 I)\u001b[39;00m\n\u001b[0;32m    321\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\alliander\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:548\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.log_marginal_likelihood\u001b[1;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[0;32m    546\u001b[0m     K, K_gradient \u001b[38;5;241m=\u001b[39m kernel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train_, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 548\u001b[0m     K \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;66;03m# Alg. 2.1, page 19, line 2 -> L = cholesky(K + sigma^2 I)\u001b[39;00m\n\u001b[0;32m    551\u001b[0m K[np\u001b[38;5;241m.\u001b[39mdiag_indices_from(K)] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\alliander\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:946\u001b[0m, in \u001b[0;36mProduct.__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m    942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m K1 \u001b[38;5;241m*\u001b[39m K2, np\u001b[38;5;241m.\u001b[39mdstack(\n\u001b[0;32m    943\u001b[0m         (K1_gradient \u001b[38;5;241m*\u001b[39m K2[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis], K2_gradient \u001b[38;5;241m*\u001b[39m K1[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis])\n\u001b[0;32m    944\u001b[0m     )\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 946\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk2(X, Y)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\alliander\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:1253\u001b[0m, in \u001b[0;36mConstantKernel.__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m eval_gradient:\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradient can only be evaluated when Y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1253\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant_value\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1257\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameter_constant_value\u001b[38;5;241m.\u001b[39mfixed:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\alliander\\lib\\site-packages\\numpy\\core\\numeric.py:344\u001b[0m, in \u001b[0;36mfull\u001b[1;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[0;32m    342\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m asarray(fill_value)\n\u001b[0;32m    343\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m fill_value\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m--> 344\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m multiarray\u001b[38;5;241m.\u001b[39mcopyto(a, fill_value, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 75.7 GiB for an array with shape (100800, 100800) and data type float64"
     ]
    }
   ],
   "source": [
    "def predict(train_on, test_on, weeks, split_on, df_x, df_y):\n",
    "    limit = 0\n",
    "\n",
    "    Xs, ys = split_on(df_x, df_y, weeks, limit)\n",
    "\n",
    "    x_train = Xs[train_on]\n",
    "    y_train = ys[train_on]\n",
    "    x_test = Xs[test_on]\n",
    "    y_test = ys[test_on]\n",
    "\n",
    "#     df_xg_predict = XGboost_regression(x_train, y_train, x_test)\n",
    "    df_gp_predict = GaussianProcess_regression(x_train, y_train, x_test)\n",
    "    \n",
    "    return df_xg_predict, df_gp_predict, y_test\n",
    "\n",
    "df_xg_predict, df_gp_predict, df_true_P = predict(4, 0, 2, split_on_stations, df_x, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f72faa9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6263227513227513 12.16585012768159\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M_VALUE_P</th>\n",
       "      <th>M_VALUE_Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.022493</td>\n",
       "      <td>0.020927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.009423</td>\n",
       "      <td>-0.012755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.408871</td>\n",
       "      <td>-0.612381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.429829</td>\n",
       "      <td>0.032674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027117</td>\n",
       "      <td>0.032784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>0.001077</td>\n",
       "      <td>-0.001037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044</th>\n",
       "      <td>-2.652431</td>\n",
       "      <td>-0.011984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>7.646673</td>\n",
       "      <td>1.102760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>-0.022493</td>\n",
       "      <td>0.020927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>-3.285126</td>\n",
       "      <td>0.779621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6048 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      M_VALUE_P  M_VALUE_Q\n",
       "0     -0.022493   0.020927\n",
       "1     -0.009423  -0.012755\n",
       "2      0.408871  -0.612381\n",
       "3      0.429829   0.032674\n",
       "4      0.027117   0.032784\n",
       "...         ...        ...\n",
       "6043   0.001077  -0.001037\n",
       "6044  -2.652431  -0.011984\n",
       "6045   7.646673   1.102760\n",
       "6046  -0.022493   0.020927\n",
       "6047  -3.285126   0.779621\n",
       "\n",
       "[6048 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P,_ = predict_sign(df_xg_predict, df_true_P)\n",
    "mse = mean_squared_error(df_true_P, df_xg_predict)\n",
    "\n",
    "print(P, mse)\n",
    "df_xg_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bafe7c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_true_P' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m    Because the training and testing strips the data of the name labels of the fields it is required to recombine \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    the model predictions with the field and station labels, as shown here below.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# First combine on index, so that the labels and predictions get properly reassigned\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m comp_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\u001b[43mdf_true_P\u001b[49m, df_y, left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m comp_df \u001b[38;5;241m=\u001b[39m comp_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM_VALUE_P_x\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM_VALUE_Q_x\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     10\u001b[0m comp_df \u001b[38;5;241m=\u001b[39m comp_df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM_VALUE_P_y\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM_VALUE_P\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM_VALUE_Q_y\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM_VALUE_Q\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_true_P' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Because the training and testing strips the data of the name labels of the fields it is required to recombine \n",
    "    the model predictions with the field and station labels, as shown here below.\n",
    "\n",
    "''' \n",
    "\n",
    "# First combine on index, so that the labels and predictions get properly reassigned\n",
    "comp_df = pd.merge(df_true_P, df_y, left_index=True, right_index=True)\n",
    "comp_df = comp_df.drop(columns=['M_VALUE_P_x', 'M_VALUE_Q_x'])\n",
    "comp_df = comp_df.rename(columns={\"M_VALUE_P_y\": \"M_VALUE_P\", \"M_VALUE_Q_y\": \"M_VALUE_Q\"})\n",
    "\n",
    "# set indices of predictions to be same as indices of true value\n",
    "df_xg_predict = df_xg_predict.set_index(comp_df.index)\n",
    "df_gp_predict = df_gp_predict.set_index(comp_df.index)\n",
    "\n",
    "# then add predictions on index to the dataframe\n",
    "comp_df = pd.merge(df_xg_predict, comp_df, left_index=True, right_index=True)\n",
    "comp_df = pd.merge(df_gp_predict, comp_df, left_index=True, right_index=True)\n",
    "comp_df\n",
    "\n",
    "station_comp_df = comp_df[comp_df[\"STATION\"]==\"Dtn\"]\n",
    "final_comp_df = station_comp_df[station_comp_df[\"FIELD\"]==\"INSTAL2\"]\n",
    "final_comp_df\n",
    "\n",
    "limit=60\n",
    "xg_pred_P = final_comp_df[\"M_VALUE_P_x\"].to_list()[:limit]\n",
    "gp_pred_P = final_comp_df[\"M_VALUE_P\"].to_list()[:limit]\n",
    "true_P = final_comp_df[\"M_VALUE_P_y\"].to_list()[:limit]\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Comparing power prediction for Dtn, INSTAL2 trained on 3 weeks data from different substations\")\n",
    "plt.plot(xg_pred_P, label='XGBoost power prediction')\n",
    "plt.plot(gp_pred_P, label='Gaussian Process power prediction')\n",
    "plt.plot(true_P, label = 'True active power')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Timestep (per 5 min)\")\n",
    "plt.ylabel(\"Power (MW)\")\n",
    "plt.savefig('temporal_2weeks.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d517fe20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
